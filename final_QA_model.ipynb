{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ef73993a-0913-437e-8289-6dede6c179d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "import torch\n",
    "import random\n",
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchmetrics import F1Score, Precision, Accuracy\n",
    "from transformers import MT5ForConditionalGeneration, MT5Tokenizer\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "import pytorch_lightning as pl\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "from torch.nn import functional as F\n",
    "import re\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from huggingface_hub.hf_api import HfFolder\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from huggingface_hub.hf_api import HfFolder\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from random import shuffle\n",
    "HfFolder.save_token('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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a80fc38f-0ae4-459e-a082-5be98659525b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.disable(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c908a3fe-3201-4e78-bd1f-75e9b2b7d81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1689e70e-8794-486e-93fd-462edf917411",
   "metadata": {},
   "outputs": [],
   "source": [
    "miracl_ru = load_dataset('miracl/miracl', 'ru')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b17043da-9bfe-4e4d-b0e5-4a7bbb6041e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "miracl_en = load_dataset('miracl/miracl', 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "82d5d3d9-36a9-456f-84e7-9d631bb03f8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "miracl_es = load_dataset('miracl/miracl', 'es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4fac53ac-1315-4447-a078-c2ca5760d877",
   "metadata": {},
   "outputs": [],
   "source": [
    "miracl_fi = load_dataset('miracl/miracl', 'fi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "029951ef-6ae2-4a59-a444-c79aaa83395b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, language='russian'):\n",
    "    \"\"\"\n",
    "    Удаляет стоп-слова, специальные символы и знаки препинания из текста.\n",
    "\n",
    "    Args:\n",
    "        text: Текст для обработки.\n",
    "        language: Язык текста (например, 'russian', 'english').\n",
    "\n",
    "    Returns:\n",
    "        Обработанный текст.\n",
    "    \"\"\"\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) # Удаляем специальные символы и знаки препинания\n",
    "    text = text.lower() # Переводим текст в нижний регистр\n",
    "    '''stop_words = set(stopwords.words(language)) \n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    text = \" \".join(words)'''\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5b218452-1221-47b7-8080-6cee5d8e8013",
   "metadata": {},
   "outputs": [],
   "source": [
    "sasha = pd.read_csv('final_combined_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "632e4f07-1fa2-4ddf-a8e8-89c62b11c763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12030, 3)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sasha.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d7014f9d-87cc-43ab-a2cb-18d5b949c66f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#training set:\n",
    "train_data = []\n",
    "\n",
    "\n",
    "for i in range(sasha.shape[0]):\n",
    "    temp_dict = {}\n",
    "    temp_dict['question'] = preprocess_text(sasha.iloc[i]['question'])\n",
    "    temp_dict['answer'] = preprocess_text(sasha.iloc[i]['answer'])\n",
    "    temp_dict['label'] = sasha.iloc[i]['label']\n",
    "\n",
    "for data in miracl_ru['train']:\n",
    "    for neg in data['negative_passages']:\n",
    "        temp_dict = {}\n",
    "        temp_dict['question'] = preprocess_text(data['query'])\n",
    "        temp_dict['answer'] = preprocess_text(neg['text'])\n",
    "        temp_dict['label'] = 0\n",
    "        train_data.append(temp_dict)\n",
    "    for pos in data['positive_passages']:\n",
    "        temp_dict = {}\n",
    "        temp_dict['question'] = preprocess_text(data['query'])\n",
    "        temp_dict['answer'] = preprocess_text(pos['text'])\n",
    "        temp_dict['label'] = 1\n",
    "        train_data.append(temp_dict)\n",
    "\n",
    "for data in miracl_en['train']:\n",
    "    for neg in data['negative_passages']:\n",
    "        temp_dict = {}\n",
    "        temp_dict['question'] = preprocess_text(data['query'])\n",
    "        temp_dict['answer'] = preprocess_text(neg['text'])\n",
    "        temp_dict['label'] = 0\n",
    "        train_data.append(temp_dict)\n",
    "    for pos in data['positive_passages']:\n",
    "        temp_dict = {}\n",
    "        temp_dict['question'] = preprocess_text(data['query'])\n",
    "        temp_dict['answer'] = preprocess_text(pos['text'])\n",
    "        temp_dict['label'] = 1\n",
    "        train_data.append(temp_dict)\n",
    "\n",
    "for data in miracl_es['train']:\n",
    "    for neg in data['negative_passages']:\n",
    "        temp_dict = {}\n",
    "        temp_dict['question'] = preprocess_text(data['query'])\n",
    "        temp_dict['answer'] = preprocess_text(neg['text'])\n",
    "        temp_dict['label'] = 0\n",
    "        train_data.append(temp_dict)\n",
    "    for pos in data['positive_passages']:\n",
    "        temp_dict = {}\n",
    "        temp_dict['question'] = preprocess_text(data['query'])\n",
    "        temp_dict['answer'] = preprocess_text(pos['text'])\n",
    "        temp_dict['label'] = 1\n",
    "        train_data.append(temp_dict)\n",
    "\n",
    "for data in miracl_fi['train']:\n",
    "    for neg in data['negative_passages']:\n",
    "        temp_dict = {}\n",
    "        temp_dict['question'] = preprocess_text(data['query'])\n",
    "        temp_dict['answer'] = preprocess_text(neg['text'])\n",
    "        temp_dict['label'] = 0\n",
    "        train_data.append(temp_dict)\n",
    "    for pos in data['positive_passages']:\n",
    "        temp_dict = {}\n",
    "        temp_dict['question'] = preprocess_text(data['query'])\n",
    "        temp_dict['answer'] = preprocess_text(pos['text'])\n",
    "        temp_dict['label'] = 1\n",
    "        train_data.append(temp_dict)\n",
    "'''\n",
    "for data in miracl_id['train']:\n",
    "    for neg in data['negative_passages']:\n",
    "        temp_dict = {}\n",
    "        temp_dict['question'] = data['query']\n",
    "        temp_dict['answer'] = neg['text']\n",
    "        temp_dict['label'] = 0\n",
    "        train_data.append(temp_dict)\n",
    "    for pos in data['positive_passages']:\n",
    "        temp_dict = {}\n",
    "        temp_dict['question'] = data['query']\n",
    "        temp_dict['answer'] = pos['text']\n",
    "        temp_dict['label'] = 1\n",
    "        train_data.append(temp_dict)\n",
    "'''\n",
    "shuffle(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4ecaeef8-3171-4391-9f09-8c157f58482c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QADataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        question = self.data[idx]['question']\n",
    "        answer = self.data[idx]['answer']\n",
    "        label = self.data[idx]['label']\n",
    "\n",
    "        inputs = self.tokenizer(\n",
    "            question, answer, \n",
    "            padding='max_length', \n",
    "            truncation=True, \n",
    "            max_length=self.max_length, \n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        inputs = {key: val.squeeze(0) for key, val in inputs.items()}  # убираем лишнюю размерность\n",
    "        inputs['labels'] = torch.tensor(label, dtype=torch.long)\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "018ab495-f774-4fc1-9ad6-c30b4ea51d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'class QADataset(torch.utils.data.Dataset):\\n    def __init__(self, data, tokenizer, max_length):\\n        self.data = data\\n        self.tokenizer = tokenizer\\n        self.max_length = max_length\\n        \\n        \\n        self.paraphrase_model = MBartForConditionalGeneration.from_pretrained(\\'facebook/mbart-large-50\\')\\n        self.paraphrase_tokenizer = MBart50TokenizerFast.from_pretrained(\\'facebook/mbart-large-50\\')\\n\\n    def __len__(self):\\n        return len(self.data)\\n\\n    def __getitem__(self, idx):\\n        question = self.data[idx][\\'question\\']\\n        answer = self.data[idx][\\'answer\\']\\n        label = self.data[idx][\\'label\\']\\n\\n        # Paraphrase with a probability of 0.3\\n        if random.random() < 0.3:\\n            question = self.paraphrase(question)\\n            answer = self.paraphrase(answer)\\n\\n        inputs = self.tokenizer(\\n            question, answer, \\n            padding=\\'max_length\\', \\n            truncation=True, \\n            max_length=self.max_length, \\n            return_tensors=\"pt\"\\n        )\\n\\n        inputs = {key: val.squeeze(0) for key, val in inputs.items()}  # Remove extra dimension\\n        inputs[\\'labels\\'] = torch.tensor(label, dtype=torch.long)\\n        return inputs\\n\\n    def paraphrase(self, text):\\n        \\n        input_ids = self.paraphrase_tokenizer.encode(text, return_tensors=\\'pt\\', padding=True, truncation=True)\\n\\n        \\n        with torch.no_grad():\\n            generated_ids = self.paraphrase_model.generate(input_ids, max_length=50, num_beams=5, early_stopping=True)\\n\\n        \\n        paraphrased_text = self.paraphrase_tokenizer.decode(generated_ids[0], skip_special_tokens=True)\\n        return paraphrased_text'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''class QADataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        \n",
    "        self.paraphrase_model = MBartForConditionalGeneration.from_pretrained('facebook/mbart-large-50')\n",
    "        self.paraphrase_tokenizer = MBart50TokenizerFast.from_pretrained('facebook/mbart-large-50')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        question = self.data[idx]['question']\n",
    "        answer = self.data[idx]['answer']\n",
    "        label = self.data[idx]['label']\n",
    "\n",
    "        # Paraphrase with a probability of 0.3\n",
    "        if random.random() < 0.3:\n",
    "            question = self.paraphrase(question)\n",
    "            answer = self.paraphrase(answer)\n",
    "\n",
    "        inputs = self.tokenizer(\n",
    "            question, answer, \n",
    "            padding='max_length', \n",
    "            truncation=True, \n",
    "            max_length=self.max_length, \n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        inputs = {key: val.squeeze(0) for key, val in inputs.items()}  # Remove extra dimension\n",
    "        inputs['labels'] = torch.tensor(label, dtype=torch.long)\n",
    "        return inputs\n",
    "\n",
    "    def paraphrase(self, text):\n",
    "        \n",
    "        input_ids = self.paraphrase_tokenizer.encode(text, return_tensors='pt', padding=True, truncation=True)\n",
    "\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            generated_ids = self.paraphrase_model.generate(input_ids, max_length=50, num_beams=5, early_stopping=True)\n",
    "\n",
    "        \n",
    "        paraphrased_text = self.paraphrase_tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "        return paraphrased_text'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d317c8c4-5f78-4b93-91a9-6fcb9969ee6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QAClassificationModel(pl.LightningModule):\n",
    "    def __init__(self, train_dataloader_size, model_name='bert-base-multilingual-cased', learning_rate=1e-5, dropout_prob=0.3, warmup_steps=1500):\n",
    "        super().__init__()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.dropout_prob = dropout_prob\n",
    "        self.scheduler = torch.optim.lr_scheduler.ExponentialLR\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # Инициализируем mBERT\n",
    "        self.model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "        self.model.dropout = torch.nn.Dropout(self.dropout_prob)\n",
    "\n",
    "        # Настройка LoRA\n",
    "        lora_config = LoraConfig(\n",
    "            task_type=TaskType.SEQ_CLS,\n",
    "            r=512,\n",
    "            lora_alpha=1024,\n",
    "            bias=\"all\"\n",
    "        )\n",
    "        self.model = get_peft_model(self.model, lora_config)\n",
    "\n",
    "        # Инициализируем F1-метрику для бинарной классификации\n",
    "        self.f1_metric = F1Score(num_classes=2, task='binary')\n",
    "        self.precision_metric = Precision(num_classes=2, task='binary')\n",
    "        self.accuracy_metric = Accuracy(num_classes=2, task='binary')\n",
    "\n",
    "        self.train_dataloader_size = train_dataloader_size\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids, labels=None):\n",
    "        return self.model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, labels=labels)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        outputs = self(\n",
    "            input_ids=batch['input_ids'], \n",
    "            attention_mask=batch['attention_mask'], \n",
    "            token_type_ids=batch['token_type_ids'], \n",
    "            labels=batch['labels']\n",
    "        )\n",
    "        loss = outputs.loss\n",
    "\n",
    "        preds = torch.argmax(outputs.logits, dim=1)\n",
    "        labels = batch['labels']\n",
    "        \n",
    "        accuracy = self.accuracy_metric(preds, labels)\n",
    "        self.log('train_accuracy', accuracy, prog_bar=True, logger=True)\n",
    "\n",
    "        f1 = self.f1_metric(preds, labels)\n",
    "        self.log('train_f1', f1, prog_bar=True, logger=True)\n",
    "        \n",
    "        precision = self.precision_metric(preds, labels)\n",
    "        self.log('train_precision', precision, prog_bar=True, logger=True)\n",
    "\n",
    "        # Логирование лосса\n",
    "        self.log('train_loss', loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        outputs = self(\n",
    "            input_ids=batch['input_ids'], \n",
    "            attention_mask=batch['attention_mask'], \n",
    "            token_type_ids=batch['token_type_ids'], \n",
    "            labels=batch['labels']\n",
    "        )\n",
    "        loss = outputs.loss\n",
    "\n",
    "        # Предсказания и реальные значения для расчета метрики\n",
    "        preds = torch.argmax(outputs.logits, dim=1)\n",
    "        labels = batch['labels']\n",
    "        \n",
    "        self.log('val_loss', loss, prog_bar=True, logger=True)\n",
    "        \n",
    "        accuracy = self.accuracy_metric(preds, labels)\n",
    "        self.log('val_accuracy', accuracy, prog_bar=True, logger=True)\n",
    "\n",
    "        f1 = self.f1_metric(preds, labels)\n",
    "        self.log('val_f1', f1, prog_bar=True, logger=True)\n",
    "        \n",
    "        precision = self.precision_metric(preds, labels)\n",
    "        self.log('val_precision', precision, prog_bar=True, logger=True)\n",
    "\n",
    "\n",
    "        return loss\n",
    "\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.parameters(), lr=self.learning_rate, weight_decay=0.1)\n",
    "        scheduler = self.scheduler(optimizer, gamma=0.9)\n",
    "        return [optimizer], [scheduler]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "61ab3682-ad21-495b-807d-b2f23e465c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "train_dataset = QADataset(train_data, tokenizer, max_length=256)\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "65a61a55-fd41-4142-a509-2fe165f7a5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализируем логгер TensorBoard\n",
    "logger = TensorBoardLogger(\"QA_logs\", name=\"qa_model\")\n",
    "\n",
    "checkpoint_every_epoch = ModelCheckpoint(\n",
    "    every_n_epochs=1,  # Сохранение модели после каждой эпохи\n",
    "    save_top_k=-1,     # Сохранить все чекпоинты\n",
    "    dirpath='checkpoints/',\n",
    "    filename='epoch-{epoch:02d}'  # Именование файла по номеру эпохи\n",
    ")\n",
    "\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=15,\n",
    "    logger=logger,\n",
    "    callbacks=[checkpoint_every_epoch],\n",
    "    accelerator=\"gpu\"\n",
    ")\n",
    "\n",
    "model = QAClassificationModel(len(train_data_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f5a7ca51-82f4-4ea7-ab94-7743d38b3a97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c1b974c69dd43c69e3ae8a123a24f94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model, train_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "46463797-2680-4f77-9e03-9f3dc59ec5f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor data in miracl_en['dev']:\\n    for neg in data['negative_passages']:\\n        temp_dict = {}\\n        temp_dict['question'] = preprocess_text(data['query'])\\n        temp_dict['answer'] = preprocess_text(neg['text'])\\n        temp_dict['label'] = 0\\n        val_data.append(temp_dict)\\n    for pos in data['positive_passages']:\\n        temp_dict = {}\\n        temp_dict['question'] = preprocess_text(data['query'])\\n        temp_dict['answer'] = preprocess_text(pos['text'])\\n        temp_dict['label'] = 1\\n        val_data.append(temp_dict)\\n\\n\\nfor data in miracl_es['dev']:\\n    for neg in data['negative_passages']:\\n        temp_dict = {}\\n        temp_dict['question'] = preprocess_text(data['query'])\\n        temp_dict['answer'] = preprocess_text(neg['text'])\\n        temp_dict['label'] = 0\\n        val_data.append(temp_dict)\\n    for pos in data['positive_passages']:\\n        temp_dict = {}\\n        temp_dict['question'] = preprocess_text(data['query'])\\n        temp_dict['answer'] = preprocess_text(pos['text'])\\n        temp_dict['label'] = 1\\n        val_data.append(temp_dict)\\n\\n\\nfor data in miracl_id['dev']:\\n    for neg in data['negative_passages']:\\n        temp_dict = {}\\n        temp_dict['question'] = data['query']\\n        temp_dict['answer'] = neg['text']\\n        temp_dict['label'] = 0\\n        val_data.append(temp_dict)\\n    for pos in data['positive_passages']:\\n        temp_dict = {}\\n        temp_dict['question'] = data['query']\\n        temp_dict['answer'] = pos['text']\\n        temp_dict['label'] = 1\\n        val_data.append(temp_dict)\\n\\nfor data in miracl_fi['dev']:\\n    for neg in data['negative_passages']:\\n        temp_dict = {}\\n        temp_dict['question'] = data['query']\\n        temp_dict['answer'] = neg['text']\\n        temp_dict['label'] = 0\\n        val_data.append(temp_dict)\\n    for pos in data['positive_passages']:\\n        temp_dict = {}\\n        temp_dict['question'] = data['query']\\n        temp_dict['answer'] = pos['text']\\n        temp_dict['label'] = 1\\n        val_data.append(temp_dict)\\n\""
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validation dataset:\n",
    "val_data = []\n",
    "\n",
    "for data in miracl_ru['dev']:\n",
    "    for neg in data['negative_passages']:\n",
    "        temp_dict = {}\n",
    "        temp_dict['question'] = preprocess_text(data['query'])\n",
    "        temp_dict['answer'] = preprocess_text(neg['text'])\n",
    "        temp_dict['label'] = 0\n",
    "        val_data.append(temp_dict)\n",
    "    for pos in data['positive_passages']:\n",
    "        temp_dict = {}\n",
    "        temp_dict['question'] = preprocess_text(data['query'])\n",
    "        temp_dict['answer'] = preprocess_text(pos['text'])\n",
    "        temp_dict['label'] = 1\n",
    "        val_data.append(temp_dict)\n",
    "\n",
    "'''\n",
    "for data in miracl_en['dev']:\n",
    "    for neg in data['negative_passages']:\n",
    "        temp_dict = {}\n",
    "        temp_dict['question'] = preprocess_text(data['query'])\n",
    "        temp_dict['answer'] = preprocess_text(neg['text'])\n",
    "        temp_dict['label'] = 0\n",
    "        val_data.append(temp_dict)\n",
    "    for pos in data['positive_passages']:\n",
    "        temp_dict = {}\n",
    "        temp_dict['question'] = preprocess_text(data['query'])\n",
    "        temp_dict['answer'] = preprocess_text(pos['text'])\n",
    "        temp_dict['label'] = 1\n",
    "        val_data.append(temp_dict)\n",
    "\n",
    "\n",
    "for data in miracl_es['dev']:\n",
    "    for neg in data['negative_passages']:\n",
    "        temp_dict = {}\n",
    "        temp_dict['question'] = preprocess_text(data['query'])\n",
    "        temp_dict['answer'] = preprocess_text(neg['text'])\n",
    "        temp_dict['label'] = 0\n",
    "        val_data.append(temp_dict)\n",
    "    for pos in data['positive_passages']:\n",
    "        temp_dict = {}\n",
    "        temp_dict['question'] = preprocess_text(data['query'])\n",
    "        temp_dict['answer'] = preprocess_text(pos['text'])\n",
    "        temp_dict['label'] = 1\n",
    "        val_data.append(temp_dict)\n",
    "\n",
    "\n",
    "for data in miracl_id['dev']:\n",
    "    for neg in data['negative_passages']:\n",
    "        temp_dict = {}\n",
    "        temp_dict['question'] = data['query']\n",
    "        temp_dict['answer'] = neg['text']\n",
    "        temp_dict['label'] = 0\n",
    "        val_data.append(temp_dict)\n",
    "    for pos in data['positive_passages']:\n",
    "        temp_dict = {}\n",
    "        temp_dict['question'] = data['query']\n",
    "        temp_dict['answer'] = pos['text']\n",
    "        temp_dict['label'] = 1\n",
    "        val_data.append(temp_dict)\n",
    "\n",
    "for data in miracl_fi['dev']:\n",
    "    for neg in data['negative_passages']:\n",
    "        temp_dict = {}\n",
    "        temp_dict['question'] = data['query']\n",
    "        temp_dict['answer'] = neg['text']\n",
    "        temp_dict['label'] = 0\n",
    "        val_data.append(temp_dict)\n",
    "    for pos in data['positive_passages']:\n",
    "        temp_dict = {}\n",
    "        temp_dict['question'] = data['query']\n",
    "        temp_dict['answer'] = pos['text']\n",
    "        temp_dict['label'] = 1\n",
    "        val_data.append(temp_dict)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7c409797-1891-4df0-8f38-d64ea7da10d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = QADataset(val_data, tokenizer, max_length=256)\n",
    "val_data_loader = DataLoader(val_dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a412f9ed-15b0-4976-85f7-9a18e5092005",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f36cb05048e249f9a32287d096fa1df6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "QAClassificationModel.on_validation_epoch_end() missing 1 required positional argument: 'outputs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2889/17546492.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainerStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRUNNING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m         return call._call_and_handle_interrupt(\n\u001b[0m\u001b[1;32m    640\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         )\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_TunerExitException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_validate_impl\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_provided\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_provided\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_connected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         )\n\u001b[0;32m--> 679\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    680\u001b[0m         \u001b[0;31m# remove the tensors from the validation results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_tensors_to_scalars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0;31m# RUN THE TRAINER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluating\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1018\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluation_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1019\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py\u001b[0m in \u001b[0;36m_decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0mcontext_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mcontext_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mloop_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_decorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restarting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_store_dataloader_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_run_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msetup_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py\u001b[0m in \u001b[0;36mon_run_end\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;31m# hook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_on_evaluation_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mlogged_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logged_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logged_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# free memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py\u001b[0m in \u001b[0;36m_on_evaluation_epoch_end\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0mhook_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"on_test_epoch_end\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"on_validation_epoch_end\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_callback_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m         \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_lightning_module_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logger_connector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[LightningModule]{pl_module.__class__.__name__}.{hook_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;31m# restore current_fx when nested context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: QAClassificationModel.on_validation_epoch_end() missing 1 required positional argument: 'outputs'"
     ]
    }
   ],
   "source": [
    "trainer.validate(model, val_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "abdaeb79-c05b-47ad-95cb-4bab28cb22a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'QA_logs/qa_model/version_0/checkpoints'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_callback.dirpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d7e6b44a-2d14-4be2-8393-30c049996445",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/user/QA_logs/qa_model/version_0/checkpoints'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3971/1443641704.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Загрузка модели\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mloaded_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQAClassificationModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'QA_logs/qa_model/version_0/checkpoints'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/utilities/model_helpers.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m                     \u001b[0;34m\" Please call it on the class type and make sure the return value is used.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                 )\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/core/module.py\u001b[0m in \u001b[0;36mload_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m   1580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m         \"\"\"\n\u001b[0;32m-> 1582\u001b[0;31m         loaded = _load_from_checkpoint(\n\u001b[0m\u001b[1;32m   1583\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m             \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/core/saving.py\u001b[0m in \u001b[0;36m_load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mmap_location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_location\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_default_map_location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mpl_legacy_patch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;31m# convert legacy checkpoints to the new format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/lightning_fabric/utilities/cloud_io.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(path_or_url, map_location, weights_only)\u001b[0m\n\u001b[1;32m     57\u001b[0m         )\n\u001b[1;32m     58\u001b[0m     \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_filesystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         return torch.load(\n\u001b[1;32m     61\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/fsspec/spec.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001b[0m\n\u001b[1;32m   1291\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1292\u001b[0m             \u001b[0mac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"autocommit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_intrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1293\u001b[0;31m             f = self._open(\n\u001b[0m\u001b[1;32m   1294\u001b[0m                 \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/fsspec/implementations/local.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, path, mode, block_size, **kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_mkdir\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"w\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mLocalFileOpener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtouch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/fsspec/implementations/local.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode, autocommit, fs, compression, **kwargs)\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_compression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocksize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFAULT_BUFFER_SIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/fsspec/implementations/local.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocommit\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"w\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mcompress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/user/QA_logs/qa_model/version_0/checkpoints'"
     ]
    }
   ],
   "source": [
    "checkpoint_path = checkpoint_callback.best_model_path\n",
    "\n",
    "# Загрузка модели\n",
    "loaded_model = QAClassificationModel.load_from_checkpoint('QA_logs/qa_model/version_0/checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a06394af-96dd-4c54-b019-8f96bf2c771d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating: QA_logs/ (stored 0%)\n",
      "updating: QA_logs/qa_model/ (stored 0%)\n",
      "updating: QA_logs/qa_model/version_0/ (stored 0%)\n",
      "updating: QA_logs/qa_model/version_0/hparams.yaml (deflated 16%)\n",
      "  adding: QA_logs/qa_model/version_0/events.out.tfevents.1730358072.rentserver.2889.8 (deflated 30%)\n",
      "  adding: QA_logs/qa_model/version_0/events.out.tfevents.1730336342.rentserver.2889.7 (deflated 73%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!zip -r QA_logs.zip QA_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6b157e42-d132-4c2d-a18a-3f5c3b33959b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: checkpoints/ (stored 0%)\n",
      "  adding: checkpoints/epoch-epoch=06.ckpt"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (deflated 8%)\n",
      "  adding: checkpoints/epoch-epoch=02.ckpt (deflated 8%)\n",
      "  adding: checkpoints/epoch-epoch=07.ckpt (deflated 8%)\n",
      "  adding: checkpoints/epoch-epoch=03.ckpt (deflated 8%)\n",
      "  adding: checkpoints/epoch-epoch=10.ckpt (deflated 8%)\n",
      "  adding: checkpoints/epoch-epoch=14.ckpt (deflated 8%)\n",
      "  adding: checkpoints/epoch-epoch=12.ckpt (deflated 8%)\n",
      "  adding: checkpoints/epoch-epoch=01.ckpt (deflated 8%)\n",
      "  adding: checkpoints/epoch-epoch=08.ckpt (deflated 8%)\n",
      "  adding: checkpoints/epoch-epoch=05.ckpt (deflated 8%)\n",
      "  adding: checkpoints/epoch-epoch=00.ckpt (deflated 8%)\n",
      "  adding: checkpoints/epoch-epoch=11.ckpt (deflated 8%)\n",
      "  adding: checkpoints/epoch-epoch=04.ckpt (deflated 8%)\n",
      "  adding: checkpoints/epoch-epoch=09.ckpt (deflated 8%)\n",
      "  adding: checkpoints/epoch-epoch=13.ckpt (deflated 8%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r checkpoints.zip checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c9f14ac1-1722-4bc3-be90-1df96c0a2bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c69ebc5f8aa4f378f3e6891651b6380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val_accuracy        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7905343770980835     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_f1           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5370550751686096     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.44743961095809937    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val_precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6638784408569336     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val_accuracy       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7905343770980835    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_f1          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5370550751686096    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.44743961095809937   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val_precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6638784408569336    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 0.44743961095809937,\n",
       "  'val_accuracy': 0.7905343770980835,\n",
       "  'val_f1': 0.5370550751686096,\n",
       "  'val_precision': 0.6638784408569336}]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model0 = QAClassificationModel.load_from_checkpoint('checkpoints/epoch-epoch=00.ckpt')\n",
    "trainer.validate(model0, val_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d7ba9220-580b-40c5-ac26-7b9ae95b8b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9ee779b5ce741bd8a299597b9e7d2e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val_accuracy        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7963358759880066     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_f1           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5196111798286438     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.44270768761634827    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val_precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7069928050041199     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val_accuracy       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7963358759880066    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_f1          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5196111798286438    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.44270768761634827   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val_precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7069928050041199    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 0.44270768761634827,\n",
       "  'val_accuracy': 0.7963358759880066,\n",
       "  'val_f1': 0.5196111798286438,\n",
       "  'val_precision': 0.7069928050041199}]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = QAClassificationModel.load_from_checkpoint('checkpoints/epoch-epoch=01.ckpt')\n",
    "trainer.validate(model1, val_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3991c170-7076-4a6b-9962-a74c073be907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50e188f07827451c8c20a3d4312b2c13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val_accuracy        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8016793727874756     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_f1           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5676466822624207     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.45113086700439453    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val_precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6829127073287964     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val_accuracy       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8016793727874756    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_f1          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5676466822624207    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.45113086700439453   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val_precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6829127073287964    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 0.45113086700439453,\n",
       "  'val_accuracy': 0.8016793727874756,\n",
       "  'val_f1': 0.5676466822624207,\n",
       "  'val_precision': 0.6829127073287964}]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = QAClassificationModel.load_from_checkpoint('checkpoints/epoch-epoch=02.ckpt')\n",
    "trainer.validate(model2, val_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "80171558-ea25-4e5c-ac75-0eaffd15e4a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5ce903d21ab4a09897636e873655f13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val_accuracy        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7988549470901489     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_f1           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5591896176338196     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.48394593596458435    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val_precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6769603490829468     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val_accuracy       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7988549470901489    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_f1          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5591896176338196    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.48394593596458435   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val_precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6769603490829468    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 0.48394593596458435,\n",
       "  'val_accuracy': 0.7988549470901489,\n",
       "  'val_f1': 0.5591896176338196,\n",
       "  'val_precision': 0.6769603490829468}]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = QAClassificationModel.load_from_checkpoint('checkpoints/epoch-epoch=03.ckpt')\n",
    "trainer.validate(model3, val_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c742cf76-0dc0-4b95-876c-bb034dbec486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45138f91b22845f39e42e0d9243d7c58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val_accuracy        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7959542274475098     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_f1           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5753812193870544     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5254520773887634     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val_precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.651907742023468     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val_accuracy       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7959542274475098    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_f1          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5753812193870544    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5254520773887634    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val_precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.651907742023468    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 0.5254520773887634,\n",
       "  'val_accuracy': 0.7959542274475098,\n",
       "  'val_f1': 0.5753812193870544,\n",
       "  'val_precision': 0.651907742023468}]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4 = QAClassificationModel.load_from_checkpoint('checkpoints/epoch-epoch=04.ckpt')\n",
    "trainer.validate(model4, val_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fe4fc13b-4d8f-4f49-8e72-7f6d21db66f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02516220d5354d7cae5e90791ed14626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val_accuracy        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7932060956954956     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_f1           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5712170004844666     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5775699019432068     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val_precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6468859314918518     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val_accuracy       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7932060956954956    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_f1          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5712170004844666    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5775699019432068    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val_precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6468859314918518    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 0.5775699019432068,\n",
       "  'val_accuracy': 0.7932060956954956,\n",
       "  'val_f1': 0.5712170004844666,\n",
       "  'val_precision': 0.6468859314918518}]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5 = QAClassificationModel.load_from_checkpoint('checkpoints/epoch-epoch=05.ckpt')\n",
    "trainer.validate(model5, val_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "df38fea4-ea8e-4f08-bac4-c5d53d73e4bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c378270af9004d4aa6f3fe17b67dcdc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val_accuracy        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7900000214576721     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_f1           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5740703344345093     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6405866742134094     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val_precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6332908868789673     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val_accuracy       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7900000214576721    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_f1          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5740703344345093    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6405866742134094    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val_precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6332908868789673    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 0.6405866742134094,\n",
       "  'val_accuracy': 0.7900000214576721,\n",
       "  'val_f1': 0.5740703344345093,\n",
       "  'val_precision': 0.6332908868789673}]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6 = QAClassificationModel.load_from_checkpoint('checkpoints/epoch-epoch=06.ckpt')\n",
    "trainer.validate(model6, val_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e8b08084-7113-450e-a95c-7241d48ca807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dacf8d4fb70e44b7a4e444db9ff53484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val_accuracy        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7889313101768494     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_f1           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5748398900032043     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6948949694633484     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val_precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6304988861083984     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val_accuracy       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7889313101768494    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_f1          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5748398900032043    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6948949694633484    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val_precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6304988861083984    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 0.6948949694633484,\n",
       "  'val_accuracy': 0.7889313101768494,\n",
       "  'val_f1': 0.5748398900032043,\n",
       "  'val_precision': 0.6304988861083984}]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model7 = QAClassificationModel.load_from_checkpoint('checkpoints/epoch-epoch=07.ckpt')\n",
    "trainer.validate(model7, val_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cd07f69d-4f9a-46ad-92c6-9b07e63eb956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92167d296f5348119f745d42599b835d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val_accuracy        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7858778834342957     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_f1           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5696620941162109     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.746492326259613     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val_precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6229051351547241     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val_accuracy       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7858778834342957    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_f1          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5696620941162109    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.746492326259613    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val_precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6229051351547241    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 0.746492326259613,\n",
       "  'val_accuracy': 0.7858778834342957,\n",
       "  'val_f1': 0.5696620941162109,\n",
       "  'val_precision': 0.6229051351547241}]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model8 = QAClassificationModel.load_from_checkpoint('checkpoints/epoch-epoch=08.ckpt')\n",
    "trainer.validate(model8, val_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fd11840b-1b13-443b-a283-41984ca655a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74577d9e1ebc470dbdc9c125d6b8008b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val_accuracy        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7803053259849548     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_f1           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5868349075317383     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8216138482093811     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val_precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5974540710449219     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val_accuracy       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7803053259849548    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_f1          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5868349075317383    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8216138482093811    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val_precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5974540710449219    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 0.8216138482093811,\n",
       "  'val_accuracy': 0.7803053259849548,\n",
       "  'val_f1': 0.5868349075317383,\n",
       "  'val_precision': 0.5974540710449219}]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model9 = QAClassificationModel.load_from_checkpoint('checkpoints/epoch-epoch=09.ckpt')\n",
    "trainer.validate(model9, val_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "24dbc920-17c7-4d06-9a06-7b9b0cedb7b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2ff8d08b716460bbc80343d2696a23b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val_accuracy        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7732061147689819     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_f1           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5918599963188171     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9110121726989746     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val_precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5758755207061768     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val_accuracy       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7732061147689819    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_f1          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5918599963188171    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9110121726989746    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val_precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5758755207061768    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 0.9110121726989746,\n",
       "  'val_accuracy': 0.7732061147689819,\n",
       "  'val_f1': 0.5918599963188171,\n",
       "  'val_precision': 0.5758755207061768}]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model10 = QAClassificationModel.load_from_checkpoint('checkpoints/epoch-epoch=10.ckpt')\n",
    "trainer.validate(model10, val_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d90c220a-7185-49ff-a782-9c80fdc048b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75b5504a18c84d0b9818074640d37196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val_accuracy        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7661831974983215     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_f1           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5956545472145081     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.0004640817642212     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val_precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.559167742729187     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val_accuracy       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7661831974983215    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_f1          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5956545472145081    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.0004640817642212    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val_precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.559167742729187    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 1.0004640817642212,\n",
       "  'val_accuracy': 0.7661831974983215,\n",
       "  'val_f1': 0.5956545472145081,\n",
       "  'val_precision': 0.559167742729187}]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model11 = QAClassificationModel.load_from_checkpoint('checkpoints/epoch-epoch=11.ckpt')\n",
    "trainer.validate(model11, val_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c64e3de4-e35a-42be-b1cf-3df278621c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ecce7c87ded4ef29395d76e6a6bcb3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val_accuracy        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7834351062774658     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_f1           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5684017539024353     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.0384217500686646     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val_precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6133360862731934     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val_accuracy       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7834351062774658    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_f1          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5684017539024353    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.0384217500686646    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val_precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6133360862731934    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 1.0384217500686646,\n",
       "  'val_accuracy': 0.7834351062774658,\n",
       "  'val_f1': 0.5684017539024353,\n",
       "  'val_precision': 0.6133360862731934}]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model14 = QAClassificationModel.load_from_checkpoint('checkpoints/epoch-epoch=14.ckpt')\n",
    "trainer.validate(model14, val_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61578105-ea0c-4bc2-b7a8-95a311d2d332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e0989b6b-bbd1-438d-9378-70c49b7dd646",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'VK очень крутая команда?'\n",
    "answer = 'Да, VK очень крутая команда' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1b0ebcab-2530-4d89-92ed-419b150d8adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  101,   159, 11733, 20598,   551, 14360, 54563, 24052,   136,   102,\n",
       "         30417,   117,   159, 11733, 20598,   551, 14360, 54563, 24052,   102,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0]),\n",
       " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "30ee9a16-608a-45ab-8fc8-069f3f82ccd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = tokenizer(\n",
    "                question, answer, \n",
    "                padding='max_length', \n",
    "                truncation=True, \n",
    "                max_length=256, \n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "input_ = {key: val.squeeze(0) for key, val in input_.items()}\n",
    "preds = torch.argmax(model2(\n",
    "        input_ids=input_['input_ids'].reshape(1,-1), \n",
    "        token_type_ids=input_['token_type_ids'].reshape(1,-1), \n",
    "        attention_mask=input_['attention_mask'].reshape(1,-1)\n",
    "    ).logits, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c62786f6-a9ab-4271-a457-8a3aecae9147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(question, answer):\n",
    "\n",
    "    class QAClassificationModel(pl.LightningModule):\n",
    "        def __init__(self, train_dataloader_size, model_name='bert-base-multilingual-cased', learning_rate=1e-5, dropout_prob=0.3, warmup_steps=1500):\n",
    "            super().__init__()\n",
    "            self.learning_rate = learning_rate\n",
    "            self.dropout_prob = dropout_prob\n",
    "            self.scheduler = torch.optim.lr_scheduler.ExponentialLR\n",
    "            self.warmup_steps = warmup_steps\n",
    "            self.save_hyperparameters()\n",
    "    \n",
    "            # Инициализируем mBERT\n",
    "            self.model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2).to('cuda')\n",
    "            self.model.dropout = torch.nn.Dropout(self.dropout_prob)\n",
    "    \n",
    "            # Настройка LoRA\n",
    "            lora_config = LoraConfig(\n",
    "                task_type=TaskType.SEQ_CLS,\n",
    "                r=512,\n",
    "                lora_alpha=1024,\n",
    "                bias=\"all\"\n",
    "            )\n",
    "            self.model = get_peft_model(self.model, lora_config)\n",
    "    \n",
    "            # Инициализируем F1-метрику для бинарной классификации\n",
    "            self.f1_metric = F1Score(num_classes=2, task='binary')\n",
    "            self.precision_metric = Precision(num_classes=2, task='binary')\n",
    "            self.accuracy_metric = Accuracy(num_classes=2, task='binary')\n",
    "    \n",
    "            self.train_dataloader_size = train_dataloader_size\n",
    "    \n",
    "        def forward(self, input_ids, attention_mask, token_type_ids, labels=None):\n",
    "            return self.model(input_ids=input_ids.to('cuda'), attention_mask=attention_mask.to('cuda'), token_type_ids=token_type_ids.to('cuda'), labels=labels)\n",
    "    \n",
    "        def training_step(self, batch, batch_idx):\n",
    "            outputs = self(\n",
    "                input_ids=batch['input_ids'], \n",
    "                attention_mask=batch['attention_mask'], \n",
    "                token_type_ids=batch['token_type_ids'], \n",
    "                labels=batch['labels']\n",
    "            ).to('cuda')\n",
    "            loss = outputs.loss\n",
    "    \n",
    "            preds = torch.argmax(outputs.logits, dim=1).to('cuda')\n",
    "            labels = batch['labels']\n",
    "            \n",
    "            accuracy = self.accuracy_metric(preds, labels)\n",
    "            self.log('train_accuracy', accuracy, prog_bar=True, logger=True)\n",
    "    \n",
    "            f1 = self.f1_metric(preds, labels)\n",
    "            self.log('train_f1', f1, prog_bar=True, logger=True)\n",
    "            \n",
    "            precision = self.precision_metric(preds, labels)\n",
    "            self.log('train_precision', precision, prog_bar=True, logger=True)\n",
    "    \n",
    "            # Логирование лосса\n",
    "            self.log('train_loss', loss, prog_bar=True, logger=True)\n",
    "            return loss\n",
    "    \n",
    "        def validation_step(self, batch, batch_idx):\n",
    "            outputs = self(\n",
    "                input_ids=batch['input_ids'], \n",
    "                attention_mask=batch['attention_mask'], \n",
    "                token_type_ids=batch['token_type_ids'], \n",
    "                labels=batch['labels']\n",
    "            )\n",
    "            loss = outputs.loss\n",
    "    \n",
    "            # Предсказания и реальные значения для расчета метрики\n",
    "            preds = torch.argmax(outputs.logits, dim=1)\n",
    "            labels = batch['labels']\n",
    "            \n",
    "            self.log('val_loss', loss, prog_bar=True, logger=True)\n",
    "            \n",
    "            accuracy = self.accuracy_metric(preds, labels)\n",
    "            self.log('val_accuracy', accuracy, prog_bar=True, logger=True)\n",
    "    \n",
    "            f1 = self.f1_metric(preds, labels)\n",
    "            self.log('val_f1', f1, prog_bar=True, logger=True)\n",
    "            \n",
    "            precision = self.precision_metric(preds, labels)\n",
    "            self.log('val_precision', precision, prog_bar=True, logger=True)\n",
    "    \n",
    "    \n",
    "            return loss\n",
    "    \n",
    "        \n",
    "        def configure_optimizers(self):\n",
    "            optimizer = AdamW(self.parameters(), lr=self.learning_rate, weight_decay=0.1)\n",
    "            scheduler = self.scheduler(optimizer, gamma=0.9)\n",
    "            return [optimizer], [scheduler]\n",
    "\n",
    "    model2 = QAClassificationModel.load_from_checkpoint('checkpoints/epoch-epoch=02.ckpt')\n",
    "\n",
    "    \n",
    "    input_ = tokenizer(\n",
    "                question, answer, \n",
    "                padding='max_length', \n",
    "                truncation=True, \n",
    "                max_length=256, \n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "    input_ = {key: val.squeeze(0) for key, val in input_.items()}\n",
    "    preds = torch.argmax(model2(\n",
    "        input_ids=input_['input_ids'].reshape(1,-1), \n",
    "        token_type_ids=input_['token_type_ids'].reshape(1,-1), \n",
    "        attention_mask=input_['attention_mask'].reshape(1,-1)\n",
    "    ).logits, dim=1)\n",
    "    return int(preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ba60a4d0-5237-493c-8553-4561f0b45ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "da6d5706-5dac-4d9b-8d4f-631446ed1228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_result('Я Марат', 'Он негр')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13c89cd-fc82-4055-8a13-c11aec79620d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(text):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
